# import library
import os
import shutil
from shutil import copyfile
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import layers, models

root_dir = 'C:\\Users\\Krisa\\Documents\\.College\\PCD\\Identifikasi daging\\Dataset Daging Hewan Ternak'

for rootdir, dirs, files in os.walk(root_dir):
    for subdir in dirs:
        print(os.path.join(rootdir, subdir))
        
TESTING_DIR = 'C:\\Users\\Krisa\\Documents\\.College\\PCD\\Identifikasi daging\\Dataset Daging Hewan Ternak\\Testing'
TRAINING_DIR =  'C:\\Users\\Krisa\\Documents\\.College\\PCD\\Identifikasi daging\\Dataset Daging Hewan Ternak\\Training'

TESTING_AYAM_DIR = os.path.join(TESTING_DIR, 'Ayam//')
TRAINING_AYAM_DIR = os.path.join(TRAINING_DIR, 'Ayam//')

TESTING_BABI_DIR = os.path.join(TESTING_DIR, 'Babi//')
TRAINING_BABI_DIR = os.path.join(TRAINING_DIR, 'Babi//')

TESTING_KAMBING_DIR = os.path.join(TESTING_DIR, 'Kambing//')
TRAINING_KAMBING_DIR = os.path.join(TRAINING_DIR, 'Kambing//')

TESTING_KELINCI_DIR = os.path.join(TESTING_DIR, 'Kelinci//')
TRAINING_KELINCI_DIR = os.path.join(TRAINING_DIR, 'Kelinci//')

TESTING_KERBAU_DIR = os.path.join(TESTING_DIR, 'Kerbau//')
TRAINING_KERBAU_DIR = os.path.join(TRAINING_DIR, 'Kerbau//')

TESTING_SAPI_DIR = os.path.join(TESTING_DIR, 'Sapi//')
TRAINING_SAPI_DIR = os.path.join(TRAINING_DIR, 'Sapi//')

TESTING_UNTA_DIR = os.path.join(TESTING_DIR, 'Unta//')
TRAINING_UNTA_DIR = os.path.join(TRAINING_DIR, 'Unta//')

print(f"\n\nThere are {len(os.listdir(TRAINING_AYAM_DIR))} images of Ayam for training")
print(f"There are {len(os.listdir(TESTING_AYAM_DIR))} images of Ayam for testing")

print(f"\n\nThere are {len(os.listdir(TRAINING_BABI_DIR))} images of Babi for training")
print(f"There are {len(os.listdir(TESTING_BABI_DIR))} images of Babi for testing")

print(f"\n\nThere are {len(os.listdir(TRAINING_KAMBING_DIR))} images of Kambing for training")
print(f"There are {len(os.listdir(TESTING_KAMBING_DIR))} images of Kambing for testing")

print(f"\n\nThere are {len(os.listdir(TRAINING_KELINCI_DIR))} images of Kelinci for training")
print(f"There are {len(os.listdir(TESTING_KELINCI_DIR))} images of Kelinci for testing")

print(f"\n\nThere are {len(os.listdir(TRAINING_KERBAU_DIR))} images of Kerbau for training")
print(f"There are {len(os.listdir(TESTING_KERBAU_DIR))} images of Kerbau for training")

print(f"\n\nThere are {len(os.listdir(TRAINING_SAPI_DIR))} images of Sapi for training")
print(f"There are {len(os.listdir(TESTING_SAPI_DIR))} images of Sapi for testing")

print(f"\n\nThere are {len(os.listdir(TRAINING_UNTA_DIR))} images of Unta for training")
print(f"There are {len(os.listdir(TESTING_UNTA_DIR))} images of Unta for testing")

# Pre-processing image
def train_val_generators(TRAINING_DIR, TESTING_DIR):
    from tensorflow.keras.preprocessing.image import ImageDataGenerator

    train_datagen = ImageDataGenerator(rescale = (1.0)/(255.0))

    train_generator = train_datagen.flow_from_directory(directory = TRAINING_DIR,
                                                        batch_size = 8,
                                                        class_mode = "categorical",
                                                        target_size = (331, 331))
    
    testing_datagen = ImageDataGenerator(rescale = (1.0)/(255.0))

    testing_generator = testing_datagen.flow_from_directory(directory = TESTING_DIR,
                                                            batch_size = 8,
                                                            class_mode = "categorical",
                                                            target_size = (331, 331))
    
    return train_generator, testing_generator
    
    train_generator, testing_generator = train_val_generators(TRAINING_DIR, TESTING_DIR)
    
    from keras.applications.nasnet import NASNetLarge
from keras.layers import Input, Conv2D, Dropout, MaxPool2D, Dense, Flatten
from keras.utils import to_categorical

# Loaded pre-trained model from keras -> NASNETLarge
# include fully connected hidden layer with the weights
nasnet = NASNetLarge(include_top=True, weights='imagenet')

# add new classification layer in top of pretrained model
# with 7 output units and softmax function
# taking second-to-last layer output as input for dense layer
x = nasnet.layers[-2].output

# adding regularizers to prevent overfitting
fc1=Dense(7, kernel_regularizer=tf.keras.regularizers.l2(0.002), 
          activation='softmax')(x) 
          
#create model that takes NASNETLarge input as input
model = tf.keras.Model(inputs=nasnet.input, outputs=fc1)          

# Freezing weights of the pre-trained layers
for l in model.layers[:-2]:
    l.trainable=False
    
# compiling model
model.compile(optimizer='RMSprop',
            loss = 'squared_hinge',
            metrics=['accuracy'])
            
model.summary()

model.fit(
        train_generator,
        steps_per_epoch=len(train_generator),
        validation_data=testing_generator,
        validation_steps=len(testing_generator),
        epochs=25
        )
